# Conception d'un mod√®le de Clustering pour la d√©tection de Fausses Informations

## üìù Description du Projet

Face √† la prolif√©ration des "Fake News" au S√©n√©gal, ce projet propose une approche de d√©tection bas√©e sur l'apprentissage non supervis√©. L'objectif est de grouper les articles de presse en sujets coh√©rents et d'analyser leur susceptibilit√© √† contenir de la d√©sinformation.

La solution s'appuie sur des outils de Traitement Automatique du Langage Naturel (NLP) et des Grands Mod√®les de Langage (LLMs), notamment :
* **BERTopic & LDA** : Pour la mod√©lisation et le clustering des sujets.
* **BertSum** : Pour la g√©n√©ration de r√©sum√©s automatiques.
* **Analyse de similarit√©** : Pour classifier les articles et d√©tecter les potentiels contenus fallacieux.

Pour plus de d√©tails th√©oriques et m√©thodologiques, vous pouvez consulter le fichier `memoire_Steve SANOGO.pdf` inclus dans ce d√©p√¥t.

<figure> 
   <img src="./images/architecture.png" alt="Pipeline" width="300">
   <figcaption>Pipeline</figcaption>
</figure> 

## üìÇ Structure du D√©p√¥t

Le projet est organis√© comme suit :

### 1. `notebooks/`
Ce r√©pertoire contient les scripts Jupyter impl√©mentant le pipeline de traitement :

* **`01_data preprocessing.ipynb`** : 
    * Script d√©di√© au nettoyage et √† la normalisation des donn√©es brutes.
    * Impl√©mente les techniques d√©crites dans la section *5.2. Pr√©traitement des donn√©es* du m√©moire (nettoyage de texte, gestion des doublons, formatage).
* **`02_topic modeling BertTopic-LDA.ipynb`** : 
    * Entra√Ænement des mod√®les de topic modeling (BERTopic).
    * Connexion √† la base de donn√©es MongoDB (`articlesdb`).
    * G√©n√©ration des clusters de sujets.
* **`03_text summarization BertSUM.ipynb`** : 
    * Utilisation de mod√®les Transformers (BertSum) pour g√©n√©rer des r√©sum√©s concis des sujets identifi√©s.

### 2. `data/`
Ce r√©pertoire contient les jeux de donn√©es utilis√©s et g√©n√©r√©s par le projet :

* **`baseArticles.json`** : Donn√©es brutes issues du Web Scraping, sans aucun traitement pr√©alable.
* **`processed_baseArticles.json`** : Version nettoy√©e et pr√©trait√©e des articles, pr√™te pour l'ingestion par les mod√®les.
* **`topicsdb.json`** : Base de donn√©es finale structur√©e par sujets. Pour chaque sujet, elle contient :
    * La liste des articles associ√©s.
    * Le r√©sum√© du sujet.
    * Les mesures de similarit√© (article vs r√©sum√©).
    * Les labels de classification (Fake / NoFake).

### 3. `memoire_Steve SANOGO.pdf`
Le document complet du m√©moire, fournissant le contexte th√©orique, l'√©tat de l'art et l'analyse d√©taill√©e des r√©sultats.

## üöÄ Installation et Pr√©requis

Pour ex√©cuter les notebooks, vous aurez besoin d'un environnement Python (recommand√© : Python 3.8+ ou Google Colab) avec les biblioth√®ques suivantes :

```txt
numpy
pandas
pymongo
spacy
bertopic
transformers
torch
scikit-learn
dateparser

```

## ‚öôÔ∏è Utilisation

L'ex√©cution du projet suit une s√©quence logique :

1. **Pr√©traitement** : Lancez `01_data preprocessing.ipynb` pour nettoyer `baseArticles.json` et g√©n√©rer `processed_baseArticles.json`.
2. **Mod√©lisation** : Lancez `02_topic modeling BertTopic-LDA.ipynb` pour cr√©er les clusters de sujets √† partir des donn√©es nettoy√©es.
3. **R√©sum√© & Analyse** : Lancez `03_text summarization BertSUM.ipynb` pour g√©n√©rer les r√©sum√©s et finaliser la base `topicsdb.json`.

## üñºÔ∏è Quelques r√©sultats

<figure> 
   <img src="./images/clusters_articles.png" width="300">
   <figcaption>Clusters d'articles de la BD</figcaption>
</figure> 



<figure> 
   <img src="./images/cluster_sujet1.png" width="300">
   <figcaption>Repr√©sentation graphique du sujet 1</figcaption>
</figure>

<figure> 
   <img src="./images/cluster_sujet111.png" width="300">
   <figcaption>Repr√©sentation graphique du sujet 111</figcaption>
</figure>

---

*Ce projet a √©t√© r√©alis√© dans un cadre acad√©mique √† l'ESMT Dakar - Promotion 2020-2023.*
